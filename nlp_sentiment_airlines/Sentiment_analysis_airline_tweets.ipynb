{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis: US airlines on Twitter\n",
    "----\n",
    "\n",
    "In this Natural Language Processing project, we predict the sentiment of tweets about different US airlines. We start by preprocessing the tweets (replacing emojis by text, removing hashtags and punctuation, converting to lowercase). We then encode each tweet to a vector of integers. We use a pre-trained GloVe embedding downloaded from [this source](https://nlp.stanford.edu/projects/glove/) and create a weights matrix of the words contained in the tweets. Finally, we build, train and compare the performance of two different Recurrent Neural Network models: a bidirectional GRU and a bidirectional LSTM.\n",
    "\n",
    "The dataset we use is available [here](https://www.kaggle.com/bertcarremans/predicting-sentiment-with-text-features/data). It consists of 11,541 tweets scraped in February 2015 categorised as negative or positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline\n",
    "import emoji\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Dropout, Bidirectional, GRU, LSTM, SpatialDropout1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0          positive  @VirginAmerica plus you've added commercials t...\n",
       "1          negative  @VirginAmerica it's really aggressive to blast...\n",
       "2          negative  @VirginAmerica and it's a really big bad thing...\n",
       "3          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
       "4          positive  @VirginAmerica yes, nearly every time I fly VX..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset\n",
    "df= pd.read_csv(\"airline_tweets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Seaborn, let's have a look at the classes representation to pick an appropriate evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10d6a9208>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEICAYAAAD2u0vkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIQCAZf4PIKYgdjh3nR0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10792a7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualising the number of negative/positive reviews\n",
    "sns.set(font_scale=1.2)\n",
    "sns.countplot(y=\"airline_sentiment\", data=df, palette=\"GnBu_d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the classes are imbalanced, we won't use accuracy as a metric to assess our models performance. Instead, we will compute their $F_1$ score.\n",
    "\n",
    "We also map labels to 0 and 1 instead of \"negative\" and \"positive\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping labels\n",
    "df[\"airline_sentiment\"]= df[\"airline_sentiment\"].map({\"negative\":0, \"positive\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Preprocessing tweets\n",
    "A crucial step in Natural Language Processing projects is text preprocessing. In our case, most tweets contain hashtags and some contain emojis, as we can see from the two examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ❤️ flying @VirginAmerica. ☺️👍\n",
      "@VirginAmerica omg omg😍😍 nonstop Dallas to Austin on virgin✨😱✈️\n"
     ]
    }
   ],
   "source": [
    "# examples of tweets that need preprocessing\n",
    "print(df[\"text\"].iloc[14])\n",
    "print(df[\"text\"].iloc[261])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because emojis reflect the mood of the person using them, they can be very useful in our sentiment analysis. Instead of just removing them, we use emoji.demojize() to convert them to words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning tweets \n",
    "def preprocess(df):\n",
    "    # converting emojis to words\n",
    "    tweet= emoji.demojize(df[\"text\"])\n",
    "    # removing words starting with @ and converting to lowercase\n",
    "    words_without_at= []\n",
    "    for w in tweet.split():\n",
    "        if w.startswith(\"@\"):\n",
    "            continue\n",
    "        else:\n",
    "            words_without_at.append(str.lower(w))\n",
    "    tweet= \" \".join(words_without_at)\n",
    "    # removing non-word characters\n",
    "    words_list= re.findall(\"[\\w]+\", tweet)\n",
    "    return \" \".join(words_list)\n",
    "\n",
    "df[\"text\"]= df.apply(preprocess, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i red_heart flying smiling_face thumbs_up\n",
      "omg omg smiling_face_with_heart eyes smiling_face_with_heart eyes nonstop dallas to austin on virgin sparkles face_screaming_in_fear airplane\n"
     ]
    }
   ],
   "source": [
    "# same examples after preprocessing\n",
    "print(df[\"text\"].iloc[14])\n",
    "print(df[\"text\"].iloc[261])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, because we are using Recurrent Neural Networks in this project, we keep the stop-words. RNNs are indeed able to handle these very common words (getting rid of them actually worsened the models performance, not shown in this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Creating the weights matrix\n",
    "We create a vocabulary with the Tokenizer tool from Keras, then encode each tweet into a vector of integers. We also set a maximum size of 25 words per tweet and pad short tweets with zeros. Note that the few tweets that are longer than 25 words will be truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11541, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the tokenizer\n",
    "tok= Tokenizer()\n",
    "tok.fit_on_texts(df[\"text\"])\n",
    "vocab_size= len(tok.word_index)+1\n",
    "\n",
    "# integer encoding\n",
    "encoded_tweets= tok.texts_to_sequences(df[\"text\"])\n",
    "\n",
    "# padding reviews to a max length of 25 words (truncating reviews longer than 25)\n",
    "tweet_len= 25\n",
    "padded_tweets= pad_sequences(encoded_tweets, maxlen=tweet_len, padding=\"post\")\n",
    "padded_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load a pre-trained GloVe embedding downloaded from [here](https://nlp.stanford.edu/projects/glove/). It corresponds to a 400,000-word vocabulary where each word is represented by a 300-dimensional vector. We store it in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the pre-trained GloVe embedding\n",
    "embeddings_index= dict()\n",
    "glove= open(\"glove.6B.300d.txt\")\n",
    "dimension= 300\n",
    "for line in glove:\n",
    "    values= line.split()\n",
    "    word= values[0]\n",
    "    coefs= np.asarray(values[1:], dtype=\"float32\")\n",
    "    embeddings_index[word]= coefs\n",
    "glove.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the dictionary of pre-trained embeddings to create a matrix of weights for each word in the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a weights matrix for each word in the tweets\n",
    "embedding_matrix= np.zeros((vocab_size, dimension))\n",
    "for word, index in tok.word_index.items():\n",
    "    embedding_vector= embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index]= embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Predicting tweet sentiment with RNNs\n",
    "As mentioned previously, we cannot rely on accuracy to evaluate performance. We need to create a function that computes the $F_1$ score in order to be able to call it when compiling our models.\n",
    "\n",
    "We also split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute the F beta score (here beta=1)\n",
    "def fb_score(y_true, y_pred):\n",
    "    y_pred= K.clip(y_pred, 0, 1)\n",
    "    true_pos= K.sum(K.round(y_true*y_pred)) + K.epsilon() #to avoid /0\n",
    "    false_pos= K.sum(K.round(K.clip(y_pred-y_true, 0, 1)))\n",
    "    false_neg= K.sum(K.round(K.clip(y_true-y_pred, 0, 1)))\n",
    "    precision= true_pos / (true_pos+false_pos)\n",
    "    recall= true_pos / (true_pos+false_neg)\n",
    "    beta=1\n",
    "    fb_score= (1+beta**2) * (precision*recall) / (beta**2*precision + recall + K.epsilon())\n",
    "    return fb_score\n",
    "\n",
    "# splitting the dataset\n",
    "X_train, X_test, y_train, y_test= train_test_split(padded_tweets, df[\"airline_sentiment\"], test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bidirectional GRU\n",
    "For both models, we set `trainable=False` because our dataset is relatively small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1155/1155 [==============================] - 8s 7ms/step\n",
      "Bidirectional GRU model F1 score on test set:  0.933333346667\n"
     ]
    }
   ],
   "source": [
    "# building the GRU model\n",
    "gru_model= Sequential()\n",
    "gru_model.add(Embedding(vocab_size, dimension, weights=[embedding_matrix], trainable=False))\n",
    "gru_model.add(SpatialDropout1D(0.2))\n",
    "gru_model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
    "gru_model.add(GlobalMaxPooling1D())\n",
    "gru_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# compiling\n",
    "gru_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[fb_score])\n",
    "\n",
    "# fitting\n",
    "gru_model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=0)\n",
    "\n",
    "# evaluating the GRU on the test set\n",
    "gru_f1_score= gru_model.evaluate(X_test, y_test, batch_size=1)\n",
    "print(\"Bidirectional GRU model F1 score on test set: \", gru_f1_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With such a bidirectional GRU model, we obtain an $F_1$ score of 93.33% on the test set. Let's see if a bidirectional LSTM can beat it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1155/1155 [==============================] - 9s 8ms/step\n",
      "Bidirectional LSTM model F1 score on test set:  0.930735944589\n"
     ]
    }
   ],
   "source": [
    "# building the LSTM model\n",
    "lstm_model= Sequential() \n",
    "lstm_model.add(Embedding(vocab_size, dimension, weights=[embedding_matrix], trainable=False))\n",
    "lstm_model.add(Bidirectional(LSTM(128, return_sequences=True, dropout=0.5, recurrent_dropout=0.5)))\n",
    "lstm_model.add(GlobalMaxPooling1D())\n",
    "lstm_model.add(Dense(64, activation=\"relu\"))\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# compiling\n",
    "lstm_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[fb_score])\n",
    "\n",
    "# fitting\n",
    "lstm_model.fit(X_train, y_train, epochs=6, batch_size=64, verbose=0)\n",
    "\n",
    "# evaluating the LSTM on the test set\n",
    "lstm_f1_score= lstm_model.evaluate(X_test, y_test, batch_size=1)\n",
    "print(\"Bidirectional LSTM model F1 score on test set: \", lstm_f1_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bidirectional LSTM model has an $F_1$ score of 93.07% on the test set. This is slightly less than the $F_1$ score of the bidirectional GRU model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Conclusion\n",
    "In this sentiment classification project, we used a word embeddings approach to predict the sentiment of tweets regarding different US airlines. After preprocessing the tweets (replacing emojis by text, removing hashtags and punctuation, converting to lowercase), we encoded each of them to a vector of integers. We then took advantage of a pre-trained GloVe embedding to create a weights matrix of the tweets words. We built and trained two different Recurrent Neural Network models: a bidirectional GRU and a bidirectional LSTM. The best performance on the test set was achieved by the bidirectional GRU model with an $F_1$ score of 93.33%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
